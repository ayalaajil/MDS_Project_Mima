{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:10:44.325791: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 15:10:44.336616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741270244.350122 2671796 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741270244.354354 2671796 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 15:10:44.367519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from extractor import ExtractingPrompt\n",
    "from LLM import LLM\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/laajila/mima_newcode/clean_code/outputs/2025-02-05/14-14-20/output_20250205_144847.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ExtractingPrompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"I feel nausea, and headache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an AI assistant trained to extract structured symptoms from patient inputs based on the PRO-CTCAE dataset. You must identify and return only the symptoms mentioned, ensuring accuracy and completeness.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Identify and extract the symptoms described in the following patient statement:\\n\\n\"I feel nausea, and headache\"\\n\\nReturn only the symptoms, separated by commas if multiple, without any additional text, comments, or explanations.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.build_extraction_prompt(\"I feel nausea, and headache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laajila/miniconda3/envs/darts_env/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/laajila/miniconda3/envs/darts_env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f14cf3bcd64e62818d165acdb70fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device(s): {'': 0}\n"
     ]
    }
   ],
   "source": [
    "model = LLM(model_name=\"iRASC/BioLlama-Ko-8B\", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"I\\'m so scared, I\\'ve got these cracks at the corners of my mouth that won\\'t go away, it\\'s so painful and itchy, I\\'m so worried I\\'ll get an infection.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_extraction_prompt(dialogue: str) -> list[dict[str, str]]:\n",
    "        \n",
    "        \"\"\"\n",
    "        Builds a structured prompt instructing the LLM to extract symptoms from the provided dialogue.\n",
    "\n",
    "        :param dialogue: The dialogue text from which to extract symptoms.\n",
    "        :return: A structured list of messages in a format suitable for LLM-based chat models.\n",
    "        \"\"\"\n",
    "        dialogue = dialogue.strip()  # Ensures clean input\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a chatbot assistant trained to extract structured symptoms from patient inputs. \"\n",
    "                    \"You must identify and return only the symptoms mentioned, strictly following the PRO-CTCAE formalism to ensure accuracy and completeness. \"\n",
    "                    \"You must be concise and avoid repetitions.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Identify and extract the symptoms described in the following patient statement: \"\n",
    "                    f\"{dialogue}\"\n",
    "                    \" Return only the symptoms, separated by commas if multiple, \"\n",
    "                    \"without any additional text, comments, or explanations.\"\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_extraction_prompt(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a chatbot assistant trained to extract structured symptoms from patient inputs. You must identify and return only the symptoms mentioned, strictly following the PRO-CTCAE formalism to ensure accuracy and completeness. You must be concise and avoid repetitions.'},\n",
       " {'role': 'user',\n",
       "  'content': \"Identify and extract the symptoms described in the following patient statement: I'm so scared, I've got these cracks at the corners of my mouth that won't go away, it's so painful and itchy, I'm so worried I'll get an infection. Return only the symptoms, separated by commas if multiple, without any additional text, comments, or explanations.\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dry mouth, mouth ulcers, mouth pain, mouth itching, mouth cracks, infection, pain, itching, infection, dry mouth, mouth ulcers, mouth pain, mouth itching, mouth cracks, infection, pain, itching, infection, dry mouth, mouth ulcers, mouth pain, mouth itching, mouth cracks, infection, pain, itching, infection, dry mouth, mouth ulcers, mouth pain, mouth itching, mouth cracks, infection, pain, itching, infection, dry mouth, mouth'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from LLM import LLM\n",
    "from PromptBuilder import PromptBuilder\n",
    "from metadata import language_registers, discussion_tones\n",
    "\n",
    "import json\n",
    "from hydra.utils import get_original_cwd\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Load configuration\n",
    "\n",
    "# Load JSON configuration\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laajila/miniconda3/envs/darts_env/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:823: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/laajila/miniconda3/envs/darts_env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43b9fbac91e4fcb8c446252948bc52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device(s): {'': 0}\n"
     ]
    }
   ],
   "source": [
    "# Initialize prompt builder and LLM with values from config.\n",
    "prompt_builder = PromptBuilder()\n",
    "model = LLM(model_name=cfg[\"model\"][\"model_name\"], token=cfg[\"token\"][\"token_key\"])\n",
    "\n",
    "input_file = os.path.join(cfg[\"data\"][\"input_file\"])\n",
    "\n",
    "a = pd.read_excel(input_file, sheet_name=\"PRO\")\n",
    "\n",
    "index = (a[a['PRO-CTCAE PT'] == 'Pain and swelling at injection site']).index.values[0] + 1\n",
    "symptoms = a.iloc[:index]['PRO-CTCAE PT'].values\n",
    "symptoms = [s for s in symptoms if s != 'Other Symptoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a multi-symptoms dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dialogues:  12%|█▏        | 100/823 [12:19<1:29:06,  7.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# Build a nested dictionary with the symptoms, descriptions, and meta values.\n",
    "symptom_dict = {}\n",
    "for symptom in symptoms:\n",
    "    try:\n",
    "        symptom_dict[symptom] = {}\n",
    "        descriptions = a[a['PRO-CTCAE PT'] == symptom]['Has PRO-CTCAE Attribute PT'].values[0].split(\" || \")\n",
    "        for description in descriptions:\n",
    "            # Retrieve meta values for the description.\n",
    "            meta_vals = a[a['PRO-CTCAE PT'] == description]['PRO-CTCAE Value PT'].values[0].split(\" || \")\n",
    "            symptom_dict[symptom][description] = meta_vals\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symptom}: {e}\")\n",
    "\n",
    "# Calculate the total number of iterations for progress tracking.\n",
    "total_iterations = sum(\n",
    "    len(meta_list) \n",
    "    for symptom in symptom_dict.values() \n",
    "    for meta_list in symptom.values()\n",
    ")\n",
    "pbar = tqdm(total=total_iterations, desc=\"Generating dialogues\")\n",
    "\n",
    "# Generate the dialogue data.\n",
    "data = []\n",
    "symptom_list = list(symptom_dict.keys())\n",
    "\n",
    "for _ in range(100):  # Define how many sentences you want\n",
    "\n",
    "    num_symptoms = np.random.randint(2, min(5, len(symptom_list) + 1))  # Random number of symptoms per sentence\n",
    "    selected_symptoms = random.sample(symptom_list, num_symptoms)\n",
    "\n",
    "    descriptions = []\n",
    "    metas = []\n",
    "\n",
    "    for symptom in selected_symptoms:\n",
    "        \n",
    "        if symptom != 'Other Symptoms':\n",
    "            description = random.choice(list(symptom_dict[symptom].keys()))\n",
    "            meta = random.choice(symptom_dict[symptom][description])\n",
    "            descriptions.append(description)\n",
    "            metas.append(meta)\n",
    "\n",
    "    detail_level = np.random.choice(cfg[\"generation\"][\"detail_levels\"])\n",
    "    enumeration = np.random.choice([True, False], p=cfg[\"generation\"][\"enumeration_probability\"])\n",
    "    explicit_symptom = np.random.choice([True, False], p=cfg[\"generation\"][\"explicit_symptom_probability\"])\n",
    "    language_style = random.choice(language_registers)['name']\n",
    "    tone = random.choice(discussion_tones)['name']\n",
    "    spelling_errors = random.choice([True, False])\n",
    "\n",
    "    prompt = prompt_builder.build_prompt(\n",
    "        symptoms=selected_symptoms,\n",
    "        description=descriptions,\n",
    "        meta=metas,\n",
    "        detail_level=detail_level,\n",
    "        enumeration=enumeration,\n",
    "        explicit_symptom=explicit_symptom,\n",
    "        language_style=language_style,\n",
    "        spelling_errors=spelling_errors,\n",
    "        tone=tone\n",
    "    )\n",
    "\n",
    "    phrase_generated = model.generate_text(messages=prompt)\n",
    "\n",
    "    data.append([\n",
    "        phrase_generated, selected_symptoms, descriptions, metas, language_style, tone,\n",
    "        detail_level, enumeration, explicit_symptom, spelling_errors\n",
    "    ])\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Create a DataFrame from the generated data.\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"Dialogue_Generated\", \"Symptoms\", \"Descriptions\", \"Meta\",\n",
    "        \"Language_Style\", \"Tone\", \"Detail_Level\", \"Enumeration\",\n",
    "        \"Explicit_Symptom\", \"Spelling_Errors\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "df.to_csv(\"Many_symptoms_generated_2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
