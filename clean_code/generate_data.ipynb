{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb8db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 21:28:22.755285: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-05 21:28:22.765718: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743881302.778908 3992539 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743881302.782975 3992539 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-05 21:28:22.796682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from autocorrect import Speller\n",
    "import itertools\n",
    "import re\n",
    "from LLM import LLM\n",
    "from PromptBuilder import PromptBuilder\n",
    "from metadata import language_registers, discussion_tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623ff1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'float' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_excel('PRO-CTCAE_Questionnaire_Terminology.xls', sheet_name = 'PRO')\n",
    "index = (a [a['PRO-CTCAE PT'] == 'Pain and swelling at injection site']).index.values[0] +1 \n",
    "symptoms = a.iloc[:index]['PRO-CTCAE PT'].values\n",
    "\n",
    "Dict = {}\n",
    "\n",
    "for symptom in symptoms : \n",
    "\n",
    "    try:\n",
    "        Dict[symptom] = {}\n",
    "        descriptions_code = a[a['PRO-CTCAE PT'] == symptom]['Has PRO-CTCAE Attribute Code'].values[0].split(\" || \")\n",
    "        descriptions = a [a['PRO-CTCAE PT'] == symptom]['Has PRO-CTCAE Attribute PT'].values[0].split(\" || \")\n",
    "        for description in descriptions :\n",
    "            Dict[symptom][description]  = a[a['PRO-CTCAE PT'] == description  ]['PRO-CTCAE Value PT'].values[0].split(\" || \")\n",
    "    \n",
    "    except Exception as e :\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40993fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has been cleaned and is ready to be used\n"
     ]
    }
   ],
   "source": [
    "for el in Dict.keys():\n",
    "    for el2 in Dict[el].keys():\n",
    "        if \"Not sexually active\" in Dict[el][el2]:\n",
    "            Dict[el][el2].remove(\"Not sexually active\")\n",
    "\n",
    "del Dict['Other Symptoms']\n",
    "\n",
    "print(\"The dictionary has been cleaned and is ready to be used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfa8632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laajila/miniconda3/envs/darts_env/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:862: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/laajila/miniconda3/envs/darts_env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de3b1170fa041a18346872857784d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device(s): {'': 0}\n"
     ]
    }
   ],
   "source": [
    "model = LLM(\"iRASC/BioLlama-Ko-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b269d8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Interference (with daily activities)': ['Not at all',\n",
       "  'A little bit',\n",
       "  'Somewhat',\n",
       "  'Quite a bit',\n",
       "  'Very much'],\n",
       " 'Frequency': ['Almost constantly',\n",
       "  'Prefer not to answer',\n",
       "  'Occasionally',\n",
       "  'Frequently',\n",
       "  'Never',\n",
       "  'Rarely'],\n",
       " 'Severity': ['Very severe',\n",
       "  'Prefer not to answer',\n",
       "  'None',\n",
       "  'Not applicable',\n",
       "  'Moderate',\n",
       "  'Mild',\n",
       "  'Severe']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict['Abdominal pain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90219ac",
   "metadata": {},
   "source": [
    "## Generate one symptom per sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c76b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 200 sentences...\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "prompt_builder = PromptBuilder()\n",
    "\n",
    "data = []\n",
    "c = 0\n",
    "for symptom, descriptions in Dict.items():\n",
    "\n",
    "    # Generate all (description, meta) combinations\n",
    "    description_meta_combinations = list(itertools.product(descriptions.keys(), *descriptions.values()))\n",
    "\n",
    "    for description, *meta_combinations in description_meta_combinations:\n",
    "\n",
    "        for meta_set in meta_combinations:\n",
    "\n",
    "            if c % 100 == 0:\n",
    "                print(f\"Generating {c+100} sentences...\")\n",
    "        \n",
    "            detail_level = np.random.choice([1, 2, 3, 4, 5])\n",
    "                        \n",
    "            enumeration = np.random.choice([True, False], p=[0.2, 0.8])\n",
    "\n",
    "            explicit_symptom = np.random.choice([True, False], p=[0.2, 0.8])\n",
    "\n",
    "\n",
    "            language_style = random.choice(language_registers)['name']\n",
    "            tone = random.choice(discussion_tones)['name']\n",
    "            spelling_errors = random.choice([True, False])\n",
    "\n",
    "            prompt = prompt_builder.build_prompt(\n",
    "                symptoms=[symptom],\n",
    "                description=description,\n",
    "                meta=meta_set,\n",
    "                detail_level=detail_level,\n",
    "                enumeration=enumeration,\n",
    "                explicit_symptom=explicit_symptom,\n",
    "                language_style=language_style,\n",
    "                spelling_errors=spelling_errors,\n",
    "                tone=tone\n",
    "            )\n",
    "            \n",
    "            phrase_generated = model.generate_text(messages=prompt)\n",
    "\n",
    "            data.append([\n",
    "                phrase_generated, symptom, description, meta_set, language_style, \n",
    "                tone, detail_level, enumeration, explicit_symptom, spelling_errors\n",
    "            ])\n",
    "            c += 1\n",
    "\n",
    "            df = pd.DataFrame(data, columns=[\n",
    "                \"Dialogue_Generated\", \"Symptom\", \"Description\", \"Meta\", \n",
    "                \"Language_Style\", \"Tone\", \"Detail_Level\", \"Enumeration\", \n",
    "                \"Explicit_Symptom\", \"Spelling_Errors\"\n",
    "            ])\n",
    "\n",
    "            df.to_csv(\"Final_dataset_generated_one_symptom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d4ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "prompt_builder = PromptBuilder()\n",
    "\n",
    "data = []\n",
    "c = 0\n",
    "\n",
    "symptom_list = list(Dict.keys())\n",
    "\n",
    "# Define how many symptoms per sentence (e.g., 2 to 4 symptoms)\n",
    "min_symptoms = 2\n",
    "max_symptoms = 4\n",
    "\n",
    "for _ in range(100):  # replace this with your desired total number of examples\n",
    "\n",
    "    # Randomly sample symptoms\n",
    "    selected_symptoms = random.sample(symptom_list, k=random.randint(min_symptoms, max_symptoms))\n",
    "\n",
    "    descriptions = []\n",
    "    metas = []\n",
    "\n",
    "    # Get description + meta info for each selected symptom\n",
    "    for symptom in selected_symptoms:\n",
    "\n",
    "        descriptions_dict = Dict[symptom]\n",
    "\n",
    "        description = random.choice(list(descriptions_dict.keys()))\n",
    "\n",
    "        meta_options = descriptions_dict[description]\n",
    "\n",
    "        meta = random.choice(meta_options)\n",
    "        \n",
    "        descriptions.append((symptom, description))\n",
    "        metas.append(meta)\n",
    "\n",
    "    if c % 100 == 0:\n",
    "        print(f\"Generated {c+100} sentences...\")\n",
    "\n",
    "    # Parameters shared across the sentence\n",
    "\n",
    "    detail_level = np.random.choice([1, 2, 3, 4, 5])\n",
    "    enumeration = np.random.choice([True, False], p=[0.2, 0.8])\n",
    "    explicit_symptom = np.random.choice([True, False], p=[0.2, 0.8])\n",
    "    language_style = random.choice(language_registers)['name']\n",
    "    tone = random.choice(discussion_tones)['name']\n",
    "    spelling_errors = random.choice([True, False])\n",
    "\n",
    "    # Build the prompt using all symptoms\n",
    "    symptoms_only = [s[0] for s in descriptions]\n",
    "    descriptions_only = [s[1] for s in descriptions]\n",
    "    \n",
    "    prompt = prompt_builder.build_prompt(\n",
    "        symptoms=symptoms_only,\n",
    "        description=descriptions_only,  # assumes you support a list of descriptions\n",
    "        meta=metas,\n",
    "        detail_level=detail_level,\n",
    "        enumeration=enumeration,\n",
    "        explicit_symptom=explicit_symptom,\n",
    "        language_style=language_style,\n",
    "        spelling_errors=spelling_errors,\n",
    "        tone=tone\n",
    "    )\n",
    "\n",
    "    phrase_generated = model.generate_text(messages=prompt)\n",
    "\n",
    "    data.append([\n",
    "        phrase_generated, symptoms_only, descriptions_only, metas, \n",
    "        language_style, tone, detail_level, enumeration, \n",
    "        explicit_symptom, spelling_errors\n",
    "    ])\n",
    "    c += 1\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"Dialogue_Generated\", \"Symptoms\", \"Descriptions\", \"Metas\", \n",
    "    \"Language_Style\", \"Tone\", \"Detail_Level\", \"Enumeration\", \n",
    "    \"Explicit_Symptom\", \"Spelling_Errors\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768e9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('New_generated_multi_symptoms_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99860331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
